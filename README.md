# Learning_with__a_teacher_trainYandex
This is test ML-project. I'm practicing publishing some files
# Проект "Прогноз оттока клиентов."
## Описание проекта
Из «Бета-Банка» стали каждый месяц уходить клиенты. Маркетологи посчитали, что сохранять текущих клиентов дешевле, чем привлекать новых. </br>
Задача: </br>
 -  спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. </br>
 -  построить модель с предельно большим значением F1-меры, довести метрику до 0.59 и проверить на тестовой выборке.
 -  дополнительно измерять AUC-ROC, сравнивая её значение с F1-мерой.
## Ход исследования
1. Загрузить и подготовить данные. Пояснить порядок действий.
2. Исследовать баланс классов, обучить модель без учёта дисбаланса. 
3. Улучшить качество модели, учитывая дисбаланс классов. Обучить разные модели и найти лучшую. 
4. Провести финальное тестирование. 

## Результаты исследования
В рамках задачи рассматривался массив клиентов банка. Потребность, которая была обозначена  - спрогнозировать отток. 
Мы рассмотрели предоставленные данные без балансировки, а затем после стандартизации и прямого кодирования при помощи трех моделей - Дерево Решений, Случайный лес и Логистическая Регрессия. </br> 

Итог без учета дисбаланса:</br>  
 
                           Дерево Решения	Случайный лес	Логистическая регрессия
                                  0.56  	       0.59      	  0.33
 
                           ROC_AUC_Дерево	   ROC_AUC_Лес	ROC_AUC_Логист.регрессия
                                   0.78            0.84     	  0.76
Дерево решений показывает лучший результат f-меры у модели случайного леса при глубине в 7 и количестве деревьев 5 на выборке из 10 деревьев при max_depth: 7 - F1: 0.591
После масштабирования и апсемплинга:

                           Дерево Решения	Случайный лес	Логистическая регрессия
                                  0.54         	   0.61	             0.50

Дерево решений показывает лучший результат на апсемплинговой выборке при max_depth: 6 - F1: 0.5

Auc_roc на валидационной выборке:

* Дерево Решений:             0.761
* Случайный лес:              0.839
* Логистическая регрессия:    0.756

Понимаем, что лучший вариант - дерево решений. Проверяем его на тестовой выборке и сравниваем с константной выборкой:</br>

f-мера: 

- Случайный лес:            0.592
- Константная модель:       0.349

Точность на тестовой выборке(Доля угаданных в общем количестве решений, определенных как верные):  0.535
Полнота на тестовой выборке (Доля угаданных, среди всех верных):   0.662
